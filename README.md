Email Analysis Backend

This is an email analysis backend using data-driven models, machine learning methods and NLP procedures. F-score accuracies are compared to SVMLight and MegaM.

Analysis components inluding spam detection, sentiment classificaton, name entity recognization, POS tagging and homophone correction.

---------------------------------
I. Spam & Sentiment Analysis
---------------------------------
To run the code for Spam & Sentiment analysis, we need to run the three programs seperately:

For nbformat.py, use command: python3 nbformat.py TARGET_FILE TRAINING_FILE,
in which TARGET_FILE contains training sets, TRAINING_FILE is the formatted training file;

For nblearn.py, use command: python3 nblearn.py TRAINING_FILE MODEL_FILE,
in which TRAINING_FILE is the output file of nbformat.py, MODEL_FILE is the model file;

For nbclassify.py, use command: python3 nbclassify.py MODEL_FILE TEST_FILE,
in which MODEL_FILE is the output file of nblearn.py, TEST_FILE contains the test data sets.


-----------------------------------------------
II. Name Entity Recognization & POS Tagging
-----------------------------------------------

usage: perceplearn.py [-h devfile] [-i iter_wanted] input_path model_path

   positional arguments:
   
     input_path  path of legal formatted file as input
     
     model_path  path of model file as output
  
   optional arguments:
   
     -h  path of development data file
     
     -i  number of iteration for update the weights
     
usage: percepclassify.py [-h] model_path

   positional arguments:
   
     model_path  path of model file

   optional arguments:
   
     -h, --help  show this help message and exit


usage: postrain.py [-h devfile] [-i iter_wanted] input_path model_path

   positional arguments:
   
     input_path  path of legal formatted file as input
     
     model_path  path of model file as output
  
   optional arguments:
   
     -h  path of development data file
     
     -i  number of iteration for update the weights
  
usage: postag.py [-h] model_path

   positional arguments:
   
     model_path  path of model file
  
   optional arguments:
   
     -h, --help  show this help message and exit

usage: nelearn.py [-h devfile] [-i iter_wanted] input_path model_path

   positional arguments:
   
     input_path  path of legal formatted file as input
     
     model_path  path of model file as output
  
   optional arguments:
   
     -h  path of development data file
     
     -i  number of iteration for update the weights
  
usage: netag.py [-h] model_path

   positional arguments:
   
     model_path  path of model file

   optional arguments:
   
     -h, --help  show this help message and exit


------------------------
Homophone Correction
------------------------
####1. Approach

  - Using [CMU Sphinx](http://cmusphinx.sourceforge.net/wiki/download) [US English Generic Language Model](http://sourceforge.net/projects/cmusphinx/files/Acoustic%20and%20Language%20Models/) as Ngram model.
  - As CMU Sphinx is an ARPA-formatted Katz back-off model, using python program modelGen.py to store the 1-grams, 2-grams, 3-grams data into three dictionaries together with their probabilities and backoffs.
  - Classify is done by python program homophoneCorrection.py, which read from input line by line and compare each word in the line to see if the word we are interested, if the word is in one of the five target homophone pairs, we take its previous two words and next two words to form two trigram units, then lookup the dictionaries got from the previous precedure and get the corresponding probabilities, compared the probabilities to decide which word in the homophone pair it would be.

####2.Program Files
  - modelGen.py This program read the downloaded ARPA-formatted language model and store the data in dictionaries then write into a binary file as the model file for further classification.
~~~

Usage: modelGen.py [-h] raw_model model

  Positional arguments: 
    raw_model   This is the path of the raw model for processing as input
    model       This is the path of model file as output

  Optional arguments:
    -h, --help  show this help message and exit
~~~

  - homophoneCorrection.py This program classifies the words inputed from stdin, for each of the word in input, we decide if it is in the five homophone pairs, if yes, we look up the dictionaries got from the binary model generated by modelGen.py and calculate the probabilities. Compareing the probabilities, the program classifies the word as the one has the larger probability.
~~~

Usage: homophoneCorrection.py [-h] model_file

  Positional arguments:
    model_file  This is the model file path

  Optional arguments:
    -h, --help  show this help message and exit
~~~

